{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd5c1522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "432dd223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# poetry add docx2txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e9491ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain import hub\n",
    "from langchain.document_loaders import Docx2txtLoader\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)  # 특정 경고 유형만 무시\n",
    "\n",
    "#  1. 환경 변수 로드\n",
    "load_dotenv()\n",
    "\n",
    "#  2. OpenAI API 키 확인\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not OPENAI_API_KEY:\n",
    "    raise ValueError(\"OpenAI API 키가 설정되지 않았습니다. .env 파일을 확인하세요.\")\n",
    "\n",
    "#  3. DOCX 파일 로드 및 텍스트 추출 (Docx2txtLoader 활용)\n",
    "def load_docx(file_path):\n",
    "    \"\"\"DOCX 파일에서 텍스트를 추출하는 함수.\"\"\"\n",
    "    try:\n",
    "        loader = Docx2txtLoader(file_path)\n",
    "        documents = loader.load()\n",
    "        text = \"\\n\".join([doc.page_content for doc in documents])\n",
    "        if not text.strip():\n",
    "            raise ValueError(\"문서에서 텍스트를 추출할 수 없습니다.\")\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"문서 로딩 실패: {str(e)}\")\n",
    "\n",
    "#  4. 문서 분할 함수\n",
    "def split_text(text, chunk_size=500, chunk_overlap=50):\n",
    "    \"\"\"텍스트를 지정된 크기의 청크로 분할하는 함수.\"\"\"\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len,\n",
    "    )\n",
    "    return splitter.split_text(text)\n",
    "\n",
    "#  5. 벡터 데이터베이스(FAISS) 생성 함수\n",
    "def create_vector_store(text_chunks, embedding_model):\n",
    "    \"\"\"텍스트 청크를 임베딩하고 FAISS 벡터 저장소에 저장.\"\"\"\n",
    "    try:\n",
    "        documents = [Document(page_content=chunk) for chunk in text_chunks]\n",
    "        vector_store = FAISS.from_documents(documents, embedding_model)\n",
    "        return vector_store\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"벡터 저장소 생성 실패: {str(e)}\")\n",
    "\n",
    "#  6. LLM을 활용한 질문 응답 함수\n",
    "def query_with_llm(query, vector_store):\n",
    "    \"\"\"LLM을 사용하여 검색된 문서 기반으로 답변 생성.\"\"\"\n",
    "    try:\n",
    "        # LLM 모델 설정\n",
    "        llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\")\n",
    "        \n",
    "        # 프롬프트 로드 (RAG 최적화된 LangChain Hub 프롬프트 사용)\n",
    "        #prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "        prompt = hub.pull(\"cheorhyeon/rag-prompt-korean\")\n",
    "        print(prompt)\n",
    "\n",
    "        # RetrievalQA 체인 생성\n",
    "        qa_chain = RetrievalQA.from_chain_type(\n",
    "            llm, \n",
    "            retriever=vector_store.as_retriever(),\n",
    "            chain_type_kwargs={\"prompt\": prompt}\n",
    "        )\n",
    "\n",
    "        # LLM 응답 생성\n",
    "        ai_message = qa_chain.invoke({\"query\": query})\n",
    "        print(ai_message)\n",
    "        return ai_message[\"result\"]\n",
    "\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"LLM 응답 생성 실패: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "168b9ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서 로드 완료\n",
      "문서 분할 완료: 296개 청크 생성\n",
      "벡터 저장소 생성 완료\n",
      "input_variables=['context', 'question'] input_types={} partial_variables={} metadata={'lc_hub_owner': 'cheorhyeon', 'lc_hub_repo': 'rag-prompt-korean', 'lc_hub_commit_hash': '23289ae9d525acc8cd52f2e7be1b4a2b09f527f7fa5d42287cac0ab824a4b3ca'} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template=\"\\n당신은 질문-답변(Question-Answering)을 수행하는 친절한 AI 어시스턴트입니다.\\n주어진 문맥(Context)에서 질문(Question)에 답하세요.\\n답을 모르면 '주어진 정보에서 질문에 대한 정보를 찾을 수 없습니다'라고 답하세요.\\n모든 답변은 한글로 작성하되, 기술 용어나 이름은 번역하지 마세요.\\n\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template='\\n#Question: {question}\\n\\n#Context: {context}\\n'), additional_kwargs={})]\n",
      "{'query': '총수입금액 불산입에 대하여 설명해 주세요.', 'result': '총수입금액 불산입이란 거주자가 자신의 소득금액을 계산할 때 일정한 조건에 해당하는 세금 환급액이나 일부 부가세 등을 총수입금액에 더하지 않는 것을 말합니다. 즉, 일부 법률로 인해 환급받은 세금 등은 총수입금액에 반영되지 않습니다.'}\n",
      "\n",
      " AI의 답변:\n",
      "총수입금액 불산입이란 거주자가 자신의 소득금액을 계산할 때 일정한 조건에 해당하는 세금 환급액이나 일부 부가세 등을 총수입금액에 더하지 않는 것을 말합니다. 즉, 일부 법률로 인해 환급받은 세금 등은 총수입금액에 반영되지 않습니다.\n"
     ]
    }
   ],
   "source": [
    "#  실행 예제\n",
    "if __name__ == \"__main__\":\n",
    "    # DOCX 파일 경로\n",
    "    docx_path = \"data/tax_with_table_short.docx\"\n",
    "    \n",
    "    # 1. 문서 로드\n",
    "    text = load_docx(docx_path)\n",
    "    print(\"문서 로드 완료\")\n",
    "    \n",
    "    # 2. 문서 분할\n",
    "    text_chunks = split_text(text)\n",
    "    print(f\"문서 분할 완료: {len(text_chunks)}개 청크 생성\")\n",
    "    \n",
    "    # 3. 임베딩 모델 초기화\n",
    "    embedding_model = OpenAIEmbeddings()\n",
    "    \n",
    "    # 4. 벡터 저장소 생성\n",
    "    vector_store = create_vector_store(text_chunks, embedding_model)\n",
    "    print(\"벡터 저장소 생성 완료\")\n",
    "    \n",
    "    # 5. 질의 실행\n",
    "    query = \"총수입금액 불산입에 대하여 설명해 주세요.\"\n",
    "    results = query_with_llm(query, vector_store)\n",
    "    \n",
    "    # 6. AI 응답 출력\n",
    "    print(\"\\n AI의 답변:\")\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74852591",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08e4d67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-basic-2-xujkvS_f-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
