{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47303d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "langchain gpt\n"
     ]
    }
   ],
   "source": [
    "print('langchain gpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "004cf279",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI \n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "687bbdcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['input'] input_types={} partial_variables={} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='당신은 개발자입니다.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [ (\"system\", \"당신은 개발자입니다.\") , \n",
    "     (\"user\", \"{input}\") ]\n",
    ")\n",
    "print(prompt)\n",
    "\n",
    "prompt_text = prompt.format(input=\"파이썬은 무엇인가요? 자세하게 설명해주세요\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "528f4af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x0000021CA81F6630> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000021CA85F1A30> root_client=<openai.OpenAI object at 0x0000021CA81FE840> root_async_client=<openai.AsyncOpenAI object at 0x0000021CA81E9940> model_name='meta-llama/llama-4-scout-17b-16e-instruct' temperature=0.7 model_kwargs={} openai_api_key=SecretStr('**********') openai_api_base='https://api.groq.com/openai/v1'\n"
     ]
    }
   ],
   "source": [
    "# Groq API를 사용하는 ChatOpenAI 인스턴스 생성\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ab6631f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "응답: 파이썬! 프로그래밍 세계에서 매우 인기 있는 언어 중 하나입니다. 파이썬은 1991년에 Guido van Rossum에 의해 개발된 고수준 프로그래밍 언어로, 현재는 Python Software Foundation에서 관리하고 있습니다.\n",
      "\n",
      "### 특징\n",
      "\n",
      "파이썬의 주요 특징은 다음과 같습니다.\n",
      "\n",
      "* **쉬운 학습 곡선**: 파이썬은 매우 직관적이고 읽기 쉬운 문법을 가지고 있어, 프로그래밍을 처음 시작하는 사람들도 쉽게 배울 수 있습니다.\n",
      "* **고수준 언어**: 파이썬은 하드웨어에 가까운 저수준 언어가 아닌, 높은 수준의 추상화를 제공하는 언어입니다. 이는 개발자가 하드웨어에 대한 세부 사항을 신경 쓰지 않고도 프로그래밍에 집중할 수 있음을 의미합니다.\n",
      "* **객체 지향**: 파이썬은 객체 지향 프로그래밍(OOP) 개념을 지원합니다. 이는 코드의 모듈화, 재사용 및 유지 보수성을 높여줍니다.\n",
      "* **대규모 라이브러리**: 파이썬은 방대한 라이브러리와 모듈을 보유하고 있어, 개발자가 다양한 작업을 쉽게 수행할 수 있습니다. 예를 들어, 데이터 분석, 머신러닝, 웹 개발, 자동화 등 다양한 분야에서 활용할 수 있는 라이브러리가 있습니다.\n",
      "\n",
      "### 활용 분야\n",
      "\n",
      "파이썬은 다양한 분야에서 널리 사용됩니다.\n",
      "\n",
      "* **데이터 분석 및 과학**: 파이썬은 데이터 분석, 머신러닝, 데이터 시각화 등에 매우 강력한 언어입니다. Pandas, NumPy, scikit-learn, TensorFlow 등의 라이브러리가 유명합니다.\n",
      "* **웹 개발**: 파이썬은 웹 개발에도 사용됩니다. Flask, Django 등의 웹 프레임워크가 인기가 있습니다.\n",
      "* **자동화**: 파이썬은 자동화 작업에 매우 적합합니다. 예를 들어, 파일 관리, 데이터 처리, 시스템 관리 작업 등을 자동화할 수 있습니다.\n",
      "* **교육**: 파이썬은 프로그래밍 교육에서 매우 인기 있는 언어입니다. 간단한 문법과 다양한 라이브러리로 인해 학생들이 프로그래밍 개념을 배우기에 좋습니다.\n",
      "\n",
      "### 왜 파이썬인가?\n",
      "\n",
      "파이썬을 사용하는 이유는 여러 가지가 있습니다.\n",
      "\n",
      "* **생산성**: 파이썬은 개발 속도를 빠르게 해주는 언어입니다. 간단한 문법과 높은 수준의 추상화로 인해 개발자가 빠르게 코드를 작성하고 테스트할 수 있습니다.\n",
      "* **커뮤니티**: 파이썬은 매우 활동적인 커뮤니티를 보유하고 있습니다. 다양한 온라인 자원, 튜토리얼, 라이브러리 등이 제공됩니다.\n",
      "* **크로스 플랫폼**: 파이썬은 다양한 운영 체제에서 실행할 수 있습니다. Windows, macOS, Linux 등에서 사용할 수 있습니다.\n",
      "\n",
      "결론적으로, 파이썬은 배우기 쉽고, 다양한 분야에서 활용할 수 있는 강력한 언어입니다. 생산성을 높이려는 개발자, 데이터 분석가, 학생 등에게 파이썬은 매우 좋은 선택입니다.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    response = llm.invoke(prompt_text)\n",
    "    print(\"응답:\", response.content)\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f82229",
   "metadata": {},
   "source": [
    "### LCEL\n",
    "* Prompt + LLM을 Chain으로 연결하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a862b3b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='\\n    You are an expert in AI Expert. Answer the question. \\n    <Question>: {input}에 대해 쉽게 반드시 한글로 설명해주세요.\")\\n    ')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    You are an expert in AI Expert. Answer the question. \n",
    "    <Question>: {input}에 대해 쉽게 반드시 한글로 설명해주세요.\")\n",
    "    \"\"\")                                     \n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f58f2c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n"
     ]
    }
   ],
   "source": [
    "# chain 연결 (LCEL) prompt + llm 연결\n",
    "chain = prompt | llm\n",
    "print(type(chain))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6cdee3",
   "metadata": {},
   "source": [
    "### LCEL\n",
    "* Prompt + LLM + OutputParser을 Chain으로 연결하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36dd2579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# chain 연결 (LCEL) prompt + llm + outputparser\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain2 = prompt | llm | output_parser\n",
    "print(type(chain2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86c996bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "인공지능 모델의 학습 원리는 컴퓨터가 데이터를 통해 스스로 학습하고, 이를 바탕으로 예측이나 분류 작업을 수행하는 과정입니다. 쉽게 설명해 보겠습니다.\n",
      "\n",
      "**인공지능 모델 학습의 기본 과정**\n",
      "\n",
      "1. **데이터 수집**: 인공지능 모델을 학습시키기 위해서는大量的 데이터가 필요합니다. 이 데이터는 문제에 따라 다르지만, 예를 들어 이미지, 텍스트, 소리 등이 될 수 있습니다.\n",
      "\n",
      "2. **데이터 전처리**: 수집된 데이터는 학습에 적합한 형태로 가공되어야 합니다. 예를 들어, 이미지 데이터의 경우, 이미지의 크기를 조정하거나, 불필요한 부분을 제거하는 작업 등이 필요합니다.\n",
      "\n",
      "3. **모델 선택**: 인공지능 모델에는 여러 가지 종류가 있습니다. 예를 들어, 이미지 분류 작업에는 합성곱 신경망(CNN), 자연어 처리 작업에는 순환 신경망(RNN) 또는 트랜스포머 등이 적합합니다.\n",
      "\n",
      "4. **학습**: 선택된 모델에 데이터를 입력하여 모델의 파라미터(가중치)를 조정하는 과정을 학습이라고 합니다. 이 과정에서는 모델이 데이터를 통해 스스로 패턴이나 규칙을 발견하도록 합니다.\n",
      "\n",
      "5. **손실 함수**: 모델의 성능을 평가하기 위해 손실 함수(loss function)를 사용합니다. 손실 함수는 모델의 예측 결과와 실제 값의 차이 정도를 측정합니다.\n",
      "\n",
      "6. **최적화**: 모델의 학습 목표는 손실 함수를 최소화하는 것입니다. 이를 위해 모델의 파라미터를 조정하면서 손실 함수의 값을 줄여나가는 최적화 과정을 거칩니다.\n",
      "\n",
      "**핵심 원리: 신경망과 역전파**\n",
      "\n",
      "신경망은 인간의 뇌를 모방한 모델로, 여러 층의 노드(뉴런)로 구성되어 있습니다. 각 노드는 입력값을 받아서 출력값을 생성하며, 이 과정에서 가중치와 활성화 함수를 사용합니다.\n",
      "\n",
      "역전파(Backpropagation)는 학습 과정에서 중요한 역할을 합니다. 역전파는 모델의 출력값과 실제 값의 차이를 역으로 추적하면서, 각 노드의 가중치를 어떻게 조정해야 할지 계산하는 방법입니다. 이를 통해 모델은 각 데이터에 대해 더 정확한 예측을 할 수 있도록 스스로를 조정합니다.\n",
      "\n",
      "**결론**\n",
      "\n",
      "인공지능 모델의 학습 원리는 데이터를 통해 모델이 스스로 학습하고, 이를 바탕으로 더 정확한 예측을 할 수 있도록 하는 것입니다. 이를 위해 데이터를 수집하고 전처리하며, 적절한 모델을 선택하고, 손실 함수를 통해 모델의 성능을 평가하고, 최적화 과정을 통해 모델을 개선해 나갑니다.\n"
     ]
    }
   ],
   "source": [
    "# chain 호출\n",
    "try:\n",
    "    result = chain.invoke({\"input\": \"인공지능 모델의 학습 원리\"})\n",
    "    print(type(result))\n",
    "    print(result.content)\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4dfd84c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "LangChain은 다양한 제품과 서비스를 제공하는 AI 기술 회사입니다. LangChain의 주요 제품은 다음과 같습니다.\n",
      "\n",
      "1. **LangSmith**: 랭스미스는 개발자가 랭체인 애플리케이션을 개발, 테스트 및 배포할 수 있도록 지원하는 통합 플랫폼입니다. 랭스미스를 사용하면 개발자는 대규모 언어 모델(LLM)을 더 쉽게 사용하고, 애플리케이션을 빠르게 구축하며, 모델의 성능을 모니터링하고 평가할 수 있습니다.\n",
      "\n",
      "2. **LangServe**: 랭서브는 LangChain에서 제공하는 또 다른 제품으로, 랭체인 애플리케이션을 쉽게 배포하고 관리할 수 있도록 지원합니다. 랭서브를 사용하면 개발자는 애플리케이션의 인프라 관리에 집중하지 않고, 애플리케이션 개발에 집중할 수 있습니다.\n",
      "\n",
      "3. **LangChain 커뮤니티 에디션**: 이것은 LangChain에서 제공하는 오픈소스 버전으로, 사용자가 LangChain의 다양한 기능을 경험하고, LangChain 생태계에 참여할 수 있도록 지원합니다.\n",
      "\n",
      "LangChain의 제품들은 대규모 언어 모델을 활용하여 자연어 처리, 대화형 AI, 콘텐츠 생성 등 다양한 AI 기반 애플리케이션을 개발하는 데 도움을 줍니다. 이러한 제품들은 개발자가 AI 기술을 더 쉽게 접근하고 활용할 수 있도록 지원하며, 기업과 개인이 AI 기술을 활용하여 혁신을 창출할 수 있도록 돕습니다.\n"
     ]
    }
   ],
   "source": [
    "# chain 호출\n",
    "try:\n",
    "    result = chain2.invoke({\"input\": \": LangChain의 Products(제품)는 어떤 것들이 있나요? 예를 들어 LangSmith, LangServe 같은 Product가 있어\"})\n",
    "    print(type(result))\n",
    "    print(result)\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a202ff76",
   "metadata": {},
   "source": [
    "\n",
    "### Runnable의 stream() 함수 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8cc49133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공지능 모델의 학습 원리를 설명드리겠습니다.\n",
      "\n",
      "**인공지능 모델의 학습이란?**\n",
      "\n",
      "인공지능 모델의 학습은 컴퓨터가 데이터를 분석하고 학습하여, 미래의 새로운 데이터에 대해 예측하거나 분류할 수 있는 능력을 갖추는 과정입니다. 이를 통해 컴퓨터는 사람처럼 학습하고 성장할 수 있습니다.\n",
      "\n",
      "**인공지능 모델의 학습 과정**\n",
      "\n",
      "인공지능 모델의 학습 과정은 다음과 같습니다.\n",
      "\n",
      "1. **데이터 수집**: 인공지능 모델을 학습시키기 위해서는 많은 데이터가 필요합니다. 이 데이터는 문제에 따라 다르지만, 일반적으로 이미지, 텍스트, 오디오 등 다양한 형태일 수 있습니다.\n",
      "2. **데이터 전처리**: 수집된 데이터는 학습에 적합한 형태로 변환되어야 합니다. 예를 들어, 이미지 데이터는 픽셀값으로 변환되거나, 텍스트 데이터는 단어 또는 문장으로 분리됩니다.\n",
      "3. **모델 선택**: 인공지능 모델을 선택합니다. 모델에는 신경망, 의사결정 트리, 선형 회귀 등 다양한 유형이 있습니다.\n",
      "4. **모델 학습**: 선택된 모델에 데이터를 입력하고, 모델이 데이터를 분석하고 학습합니다. 이 과정에서 모델은 데이터의 패턴을 인식하고, 예측 또는 분류를 위한 규칙을 생성합니다.\n",
      "5. **모델 평가**: 학습된 모델의 성능을 평가합니다. 이를 통해 모델의 정확도, 정밀도, 재현율 등을 측정하고, 모델의 성능을 개선할 수 있습니다.\n",
      "\n",
      "**신경망 모델의 학습 원리**\n",
      "\n",
      "신경망 모델은 인간의 뇌를 모방한 모델입니다. 신경망 모델의 학습 원리는 다음과 같습니다.\n",
      "\n",
      "1. **신경망 구조**: 신경망은 입력층, 은닉층, 출력층으로 구성됩니다. 입력층은 데이터를 입력받고, 은닉층은 데이터를 처리하고, 출력층은 결과를 출력합니다.\n",
      "2. **가중치와 편향**: 신경망의 각 노드에는 가중치와 편향이 있습니다. 가중치는 입력 데이터의 중요도를 나타내고, 편향은 출력값을 조정합니다.\n",
      "3. **활성화 함수**: 은닉층과 출력층의 노드에는 활성화 함수가 적용됩니다. 활성화 함수는 입력값을 변환하여 출력값을 생성합니다.\n",
      "4. **오류 역전파**: 신경망 모델은 오류 역전파 알고리즘을 사용하여 학습합니다. 오류 역전파는 출력층의 오류를 역으로 전파하여, 각 노드의 가중치와 편향을 업데이트합니다.\n",
      "5. **최적화**: 신경망 모델은 최적화 알고리즘을 사용하여 가중치와 편향을 업데이트합니다. 최적화 알고리즘에는 경사 하강법, RMSProp, Adam 등이 있습니다.\n",
      "\n",
      "**결론**\n",
      "\n",
      "인공지능 모델의 학습 원리는 데이터를 분석하고 학습하여, 미래의 새로운 데이터에 대해 예측하거나 분류할 수 있는 능력을 갖추는 과정입니다. 신경망 모델은 인간의 뇌를 모방한 모델로, 가중치와 편향, 활성화 함수, 오류 역전파, 최적화 알고리즘을 사용하여 학습합니다. 이를 통해 컴퓨터는 사람처럼 학습하고 성장할 수 있습니다."
     ]
    }
   ],
   "source": [
    "# 스트리밍 출력을 위한 요청\n",
    "try:\n",
    "    answer = chain2.stream({\"input\": \"인공지능 모델의 학습 원리를 자세하게 설명해주세요\"})\n",
    "\n",
    "    for token in answer:\n",
    "        # 스트림에서 받은 데이터의 내용을 출력합니다. 줄바꿈 없이 이어서 출력하고, 버퍼를 즉시 비웁니다.\n",
    "        print(token, end=\"\", flush=True)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba0932e",
   "metadata": {},
   "source": [
    "### Multi Chain\n",
    "* 첫번째 Chain의 출력이, 두번째 Chain의 입력이 된다.\n",
    "* 두개의 Chain과 Prompt + OutputParser를 LCEL로 연결하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "12afe309",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Step 1: 사용자가 입력한 장르에 따라 영화 추천\n",
    "prompt1 = ChatPromptTemplate.from_template(\"{genre} 장르에서 추천할 만한 영화를 한 편 알려주세요.\")\n",
    "\n",
    "# Step 2: 추천된 영화의 줄거리를 요약\n",
    "prompt2 = ChatPromptTemplate.from_template(\"{movie} 추전한 영화의 제목을 먼저 알려주시고, 줄을 바꾸어서 영화의 줄거리를 10문장으로 요약해 주세요.\")\n",
    "\n",
    "# OpenAI 모델 사용\n",
    "llm = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    #model=\"mistral-saba-24b\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# 체인 1: 영화 추천 (입력: 장르 → 출력: 영화 제목)\n",
    "chain1 = prompt1 | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8886447b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "추천한 영화의 제목은 '이혼 전야'입니다.\n",
      "\n",
      "영화 '이혼 전야'는 이혼을 결심한 부부가 마지막으로 함께 보내는 밤을 다루고 있습니다. 부부는 서로에 대한 감정이 식은 지 오래입니다. 그들은 서로에게 상처만 주는 관계가 되었습니다. 이혼을 결심한 그들은 마지막으로 함께 보내는 밤을 선택합니다. 이 밤을 통해 그들은 서로에 대한 감정과 이혼의 고통을 다시 한번 생각하게 됩니다. 부부의 갈등과 상처가 드러나며, 이혼의 고통이 감동 있게 그려집니다. 배우 유해진과 전혜빈이 열연한 이 영화는 부부의 관계를 깊이 있게 탐구합니다. 그들은 서로에 대한 사랑과 증오를 다시 한번 느끼게 됩니다. 이 영화는 부부의 이혼과 그 과정에서의 고통을 현실적으로 보여줍니다.\n"
     ]
    }
   ],
   "source": [
    "# 체인 2: 줄거리 요약 (입력: 영화 제목 → 출력: 줄거리)\n",
    "try:\n",
    "    chain2 = (\n",
    "        {\"movie\": chain1}  # chain1의 출력을 movie 입력 변수로 전달\n",
    "        | prompt2\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    # 실행: \"SF\" 장르의 영화 추천 및 줄거리 요약\n",
    "    response = chain2.invoke({\"genre\": \"Drama\"})\n",
    "    print(response)  \n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6df7f5c",
   "metadata": {},
   "source": [
    "### PromptTemplate 여러개 연결하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "00b4678d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatGPT 모델의 학습 원리는 다음과 같습니다.\n",
      "\n",
      "ChatGPT는 대규모 언어 모델로, 수십억 개의 매개변수를 가지고 있습니다. 이 모델은 인터넷에서 수집한 대규모 텍스트 데이터를 기반으로 학습하여 자연어 처리 능력을 키웁니다. 학습 과정에서 모델은 입력된 텍스트에 대한 다음 단어를 예측하도록 훈련되며, 이를 통해 언어의 패턴과 구조를 학습합니다.\n",
      "\n",
      "ChatGPT 모델의 장점은 다음과 같습니다.\n",
      "\n",
      "*   자연어 이해 능력: ChatGPT는 자연어 입력에 대해 높은 이해 능력을 보여주며, 사용자의 질문이나 요청을 정확하게 파악할 수 있습니다.\n",
      "*   대화 생성 능력: ChatGPT는 상황에 맞는 적절한 응답을 생성할 수 있으며, 대화의 흐름을 자연스럽게 이어갈 수 있습니다.\n",
      "*   지식 정보 제공: ChatGPT는 방대한 텍스트 데이터를 학습했기 때문에, 다양한 주제에 대한 정보를 제공할 수 있습니다.\n",
      "\n",
      "ChatGPT 모델과 비슷한 AI 모델은 다음과 있습니다.\n",
      "\n",
      "*   LLaMA\n",
      "*   PaLM \n",
      "*   BERT \n",
      "*   XLNet \n",
      "*   LaMDA\n"
     ]
    }
   ],
   "source": [
    "template_text = \"{model_name} 모델의 학습 원리를 {count} 문장으로 요약해서 한국어로 답변해 주세요.\"\n",
    "\n",
    "# PromptTemplate 인스턴스를 생성\n",
    "prompt_template = PromptTemplate.from_template(template_text)\n",
    "\n",
    "# 템플릿에 값을 채워서 프롬프트를 완성\n",
    "filled_prompt = prompt_template.format(model_name=\"ChatGPT\", count=3)\n",
    "\n",
    "# 문자열 템플릿 결합 (PromptTemplate + PromptTemplate + 문자열)\n",
    "combined_prompt = (\n",
    "              prompt_template\n",
    "              + PromptTemplate.from_template(\"\\n\\n 그리고 {model_name} 모델의 장점을 요약 정리해 주세요\")\n",
    "              + \"\\n\\n {model_name} 모델과 비슷한 AI 모델은 어떤 것이 있나요? 모델명은 {language}로 답변해 주세요.\"\n",
    ")\n",
    "combined_prompt.format(model_name=\"ChatGPT\", count=3, language=\"영어\")\n",
    "\n",
    "# OpenAI 모델 사용\n",
    "llm = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "chain = combined_prompt | llm | StrOutputParser()\n",
    "response = chain.invoke({\"model_name\":\"ChatGPT\", \"count\":3, \"language\":\"영어\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "996589d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GPT-4 모델의 학습 원리를 2 문장으로 한국어로 답변해 주세요.', 'Gemma 모델의 학습 원리를 3 문장으로 한국어로 답변해 주세요.', 'llama-4 모델의 학습 원리를 4 문장으로 한국어로 답변해 주세요.']\n"
     ]
    }
   ],
   "source": [
    "template_text = \"{model_name} 모델의 학습 원리를 {count} 문장으로 한국어로 답변해 주세요.\"\n",
    "\n",
    "# PromptTemplate 인스턴스를 생성\n",
    "prompt_template = PromptTemplate.from_template(template_text)\n",
    "\n",
    "questions = [\n",
    "    {\"model_name\": \"GPT-4\", \"count\": 2},\n",
    "    {\"model_name\": \"Gemma\", \"count\": 3},\n",
    "    {\"model_name\": \"llama-4\", \"count\": 4},\n",
    "]\n",
    "\n",
    "# 여러 개의 프롬프트를 미리 생성\n",
    "formatted_prompts = [prompt_template.format(**q) for q in questions]\n",
    "print(formatted_prompts)  # 미리 생성된 질문 목록 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "63dabf55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-4 모델은 수십억 개의 매개변수를 가진 대규모 언어 모델로, 방대한 양의 텍스트 데이터를 학습하여 자연어 처리 능력을 습득하였습니다. 이 모델은 트랜스포머 아키텍처를 기반으로 하며, 주어진 문맥에서 다음에 나타날 가능성이 높은 단어를 예측하도록 학습되었습니다.\n",
      "Gemma는 컴퓨터가 자연어 처리를 더 잘하도록 설계된 언어 모델입니다. 텍스트의 통계적 패턴을 학습하여 문장에서 다음에 나타날 가능성이 있는 단어를 예측하는 방식으로 학습합니다. 이 학습 과정은 대규모 텍스트 데이터 세트를 기반으로 수행되며, 이 과정에서 모델은 언어의 구조와 뉘앙스를 학습합니다.\n",
      "llama-4 모델은 메타에서 개발한 대규모 언어 모델입니다. 이 모델은 방대한 텍스트 데이터를 바탕으로 학습되며, 이를 통해 자연어 처리 능력을 습득합니다. 학습 과정에서 모델은 주어진 문맥에서 다음에 올 단어를 예측하도록 훈련되며, 이 과정을 통해 언어의 패턴과 구조를 학습합니다. 이를 바탕으로 llama-4 모델은 다양한 자연어 처리 작업에 활용될 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "# OpenAI 모델 사용\n",
    "llm = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "for prompt in formatted_prompts:\n",
    "    response = llm.invoke(prompt)\n",
    "    print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04bf0d8",
   "metadata": {},
   "source": [
    "### ChatPromptTemplate\n",
    "* SystemMessagePromptTemplate, HumanMessagePromptTemplate, AIMessagePromptTemplate 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "116178d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "\n",
      "딥러닝은 인공신경망을 기반으로 하는 머신러닝의 한 분야입니다. 인공신경망은 인간의 뇌를 모방하여 만든 알고리즘으로, 데이터를 처리하고 학습하는 방식입니다. 딥러닝은 이러한 인공신경망을 깊게 쌓아서 복잡한 데이터를 분석하고 학습하는 기술입니다.\n",
      "\n",
      "딥러닝은 데이터에서 패턴을 찾아내고, 이를 통해 이미지, 음성, 텍스트 등의 데이터를 분류, 인식, 생성하는 등의 작업을 수행할 수 있습니다. 예를 들어, 이미지 인식, 음성 인식, 자연어 처리, 자율 주행 자동차 등의 분야에서 딥러닝이 사용됩니다.\n",
      "\n",
      "딥러닝의 핵심 개념은 다음과 같습니다.\n",
      "\n",
      "1. **인공신경망**: 인간의 뇌를 모방하여 만든 알고리즘으로, 데이터를 처리하고 학습하는 방식입니다.\n",
      "2. **심층 학습**: 인공신경망을 깊게 쌓아서 복잡한 데이터를 분석하고 학습하는 기술입니다.\n",
      "3. **데이터**: 딥러닝은 데이터를 통해 학습합니다. 데이터는 이미지, 음성, 텍스트 등의 형태일 수 있습니다.\n",
      "4. **패턴 인식**: 딥러닝은 데이터에서 패턴을 찾아내고, 이를 통해 데이터를 분류, 인식, 생성하는 등의 작업을 수행할 수 있습니다.\n",
      "\n",
      "딥러닝의 장점은 다음과 같습니다.\n",
      "\n",
      "* **복잡한 데이터 처리**: 딥러닝은 복잡한 데이터를 처리할 수 있습니다.\n",
      "* **높은 정확도**: 딥러닝은 높은 정확도로 데이터를 분류, 인식, 생성할 수 있습니다.\n",
      "* **자동화**: 딥러닝은 데이터를 자동으로 처리하고 학습할 수 있습니다.\n",
      "\n",
      "하지만 딥러닝의 단점은 다음과 같습니다.\n",
      "\n",
      "* **대량 데이터 요구**: 딥러닝은 대량의 데이터를 요구합니다.\n",
      "* **계산 자원 요구**: 딥러닝은 많은 계산 자원을 요구합니다.\n",
      "* **해석 어려움**: 딥러닝 모델은 해석하기 어려울 수 있습니다.\n",
      "\n",
      "요약하면, 딥러닝은 인공신경망을 기반으로 하는 머신러닝의 한 분야로, 복잡한 데이터를 분석하고 학습하는 기술입니다. 딥러닝은 이미지 인식, 음성 인식, 자연어 처리, 자율 주행 자동차 등의 분야에서 사용됩니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate\n",
    ")\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 개별 메시지 템플릿 정의\n",
    "system_message = SystemMessagePromptTemplate.from_template(\n",
    "    \"당신은 {topic} 전문가입니다. 명확하고 자세하게 설명해 주세요.\"\n",
    ")\n",
    "user_message = HumanMessagePromptTemplate.from_template(\n",
    "    \"{question}\"\n",
    ")\n",
    "ai_message = AIMessagePromptTemplate.from_template(\n",
    "    \"This is an example answer about {topic}.\"\n",
    ")\n",
    "\n",
    "# ChatPromptTemplate로 메시지들을 묶기\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    system_message,\n",
    "    user_message,\n",
    "    ai_message\n",
    "])\n",
    "\n",
    "# 메시지 생성\n",
    "messages = chat_prompt.format_messages(topic=\"AI\", question=\"딥러닝은 무엇인가요?\")\n",
    "\n",
    "# LLM 호출\n",
    "llm = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "# 결과 출력\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80104c5f",
   "metadata": {},
   "source": [
    "### FewShotPromptTemplate\n",
    "* 예시를 제공 프롬프트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5f3bba74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### 태양계의 행성\n",
      "1. **수성**: 가장 작은 행성, 태양과 가깝습니다.\n",
      "2. **금성**: 매우 뜨겁고 밝은 행성입니다.\n",
      "3. **지구**: 생명체가 사는 유일한 행성입니다.\n",
      "4. **화성**: 붉은 행성, 로봇 탐사가 활발합니다.\n",
      "5. **목성**: 태양계에서 가장 큰 행성입니다.\n",
      "6. **토성**: 아름다운 고리를 가진 행성입니다.\n",
      "7. **천왕성**: 자전축이 기울어져 있습니다.\n",
      "8. **해왕성**: 태양계에서 가장 먼 행성입니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"input\": \"뉴턴의 운동 법칙을 요약해 주세요.\",\n",
    "        \"output\": \"\"\"### 뉴턴의 운동 법칙\n",
    "1. **관성의 법칙**: 힘이 작용하지 않으면 물체는 계속 같은 상태를 유지합니다.\n",
    "2. **가속도의 법칙**: 물체에 힘이 작용하면, 힘과 질량에 따라 가속도가 결정됩니다.\n",
    "3. **작용-반작용 법칙**: 모든 힘에는 크기가 같고 방향이 반대인 힘이 작용합니다.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"지구의 대기 구성 요소를 알려주세요.\",\n",
    "        \"output\": \"\"\"### 지구 대기의 구성\n",
    "- **질소 (78%)**: 대기의 대부분을 차지합니다.\n",
    "- **산소 (21%)**: 생명체가 호흡하는 데 필요합니다.\n",
    "- **아르곤 (0.93%)**: 반응성이 낮은 기체입니다.\n",
    "- **이산화탄소 (0.04%)**: 광합성 및 온실 효과에 중요한 역할을 합니다.\"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# 예제 프롬프트 템플릿\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{output}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# FewShotChatMessagePromptTemplate 적용\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "\n",
    "# 최종 프롬프트 구성\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"당신은 초등학생도 이해할 수 있도록 쉽게 설명하는 과학 교육자입니다.\"),\n",
    "        few_shot_prompt,\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 모델 생성 및 체인 구성\n",
    "#model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.0)\n",
    "model = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "chain = final_prompt | model\n",
    "\n",
    "# 테스트 실행\n",
    "result = chain.invoke({\"input\": \"태양계의 행성들을 간략히 정리해 주세요.\"})\n",
    "#result = chain.invoke({\"input\": \"양자 얽힘이 무엇인가요?\"})\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde4a8b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-basic-2-xujkvS_f-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
